{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Recreating the following for classification problem\n",
        "https://www.tensorflow.org/text/tutorials/transformer"
      ],
      "metadata": {
        "id": "aalYeMHGPiYU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfV1batAwq9j"
      },
      "source": [
        "Need tensorflow-text for using the BERT model tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFG0NDRu5mYQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dd7fea0-f99e-4423-ddc4-e683264b0f3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow-text as it is not installed.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 14.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 578.0 MB 18 kB/s \n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 55.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 66.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 438 kB 79.5 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install the nightly version of TensorFlow to use the improved\n",
        "# masking support for `tf.keras.layers.MultiHeadAttention`.\n",
        "!pip uninstall -y -q tensorflow keras tensorflow-estimator tensorflow-text\n",
        "!pip install -q -U tensorflow-text tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GYpLBSjxJmG"
      },
      "source": [
        "Import the necessary modules:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjJJyJTZYebt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_text\n",
        "from sklearn.utils import shuffle "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing necessary data preprocessing"
      ],
      "metadata": {
        "id": "i4T14r9fQead"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5IzyXpYXTIO",
        "outputId": "cf16aa50-20ba-4df2-93b3-05fc3ab18511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'twitter_validation.csv', 'twitter_training.csv', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_loc = \"./twitter_training.csv\"\n",
        "val_data_loc = \"./twitter_validation.csv\""
      ],
      "metadata": {
        "id": "I07JCtVxyOWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(training_data_loc)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QqCulADtyWDT",
        "outputId": "4ddde03c-8d5a-4ec5-84f5-6b4a2ddbfe37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       2401  Borderlands  Positive  \\\n",
              "0      2401  Borderlands  Positive   \n",
              "1      2401  Borderlands  Positive   \n",
              "2      2401  Borderlands  Positive   \n",
              "3      2401  Borderlands  Positive   \n",
              "4      2401  Borderlands  Positive   \n",
              "...     ...          ...       ...   \n",
              "74676  9200       Nvidia  Positive   \n",
              "74677  9200       Nvidia  Positive   \n",
              "74678  9200       Nvidia  Positive   \n",
              "74679  9200       Nvidia  Positive   \n",
              "74680  9200       Nvidia  Positive   \n",
              "\n",
              "      im getting on borderlands and i will murder you all ,  \n",
              "0      I am coming to the borders and I will kill you...     \n",
              "1      im getting on borderlands and i will kill you ...     \n",
              "2      im coming on borderlands and i will murder you...     \n",
              "3      im getting on borderlands 2 and i will murder ...     \n",
              "4      im getting into borderlands and i can murder y...     \n",
              "...                                                  ...     \n",
              "74676  Just realized that the Windows partition of my...     \n",
              "74677  Just realized that my Mac window partition is ...     \n",
              "74678  Just realized the windows partition of my Mac ...     \n",
              "74679  Just realized between the windows partition of...     \n",
              "74680  Just like the windows partition of my Mac is l...     \n",
              "\n",
              "[74681 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40cc27fb-ff3c-421c-9a4d-a26e0a156077\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2401</th>\n",
              "      <th>Borderlands</th>\n",
              "      <th>Positive</th>\n",
              "      <th>im getting on borderlands and i will murder you all ,</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>I am coming to the borders and I will kill you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im getting on borderlands and i will kill you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im coming on borderlands and i will murder you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im getting into borderlands and i can murder y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74676</th>\n",
              "      <td>9200</td>\n",
              "      <td>Nvidia</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Just realized that the Windows partition of my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74677</th>\n",
              "      <td>9200</td>\n",
              "      <td>Nvidia</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Just realized that my Mac window partition is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74678</th>\n",
              "      <td>9200</td>\n",
              "      <td>Nvidia</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Just realized the windows partition of my Mac ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74679</th>\n",
              "      <td>9200</td>\n",
              "      <td>Nvidia</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Just realized between the windows partition of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74680</th>\n",
              "      <td>9200</td>\n",
              "      <td>Nvidia</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Just like the windows partition of my Mac is l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>74681 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40cc27fb-ff3c-421c-9a4d-a26e0a156077')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-40cc27fb-ff3c-421c-9a4d-a26e0a156077 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-40cc27fb-ff3c-421c-9a4d-a26e0a156077');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df.columns[2:]]"
      ],
      "metadata": {
        "id": "pS4ybWKnyk60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns={\"Positive\":\"Sentiment\", \"im getting on borderlands and i will murder you all ,\":\"sentence\"})"
      ],
      "metadata": {
        "id": "iHKFQiYZyodp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sentiment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehoSJitfyqFg",
        "outputId": "76a578cb-6391-4bc0-e6d8-c6681e03a6f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Negative      22542\n",
              "Positive      20831\n",
              "Neutral       18318\n",
              "Irrelevant    12990\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df.apply(lambda x: (x[\"Sentiment\"] == \"Positive\") or (x[\"Sentiment\"] == \"Negative\"), axis=1)]"
      ],
      "metadata": {
        "id": "nNwXwOfGyxQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sentiment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn62U45gy2er",
        "outputId": "7521ce6d-40e8-46b2-db0f-0a1bfd57f74f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Negative    22542\n",
              "Positive    20831\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sentiment'] = df['Sentiment'].apply(lambda x: 1 if x == \"Positive\" else 0)"
      ],
      "metadata": {
        "id": "mQK30n9gy9jT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = shuffle(df)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "MCdnMURwzFYm",
        "outputId": "c45ade64-e68a-4513-8050-e53108225741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Sentiment                                           sentence\n",
              "64514          1                                   I love your list\n",
              "6688           0                    if you like this will regret it\n",
              "46970          0  Hey @JustinTrudeau , I read that the executive...\n",
              "53421          1  Maybe the greatest musical moment in a video w...\n",
              "844            0                                               that\n",
              "...          ...                                                ...\n",
              "24701          1  Thank You @YouTubeIndia @YTCreatorsIndia  for ...\n",
              "11040          1  Remember that it was one of the best stealth g...\n",
              "70094          0  @GhostRecon_UK fix your game. The Behemoth is ...\n",
              "4307           0                                    my pc is crying\n",
              "19280          1  Episode 100! It's a thing! It's a thing that h...\n",
              "\n",
              "[43373 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-53a569b8-e0a4-49f0-ad6e-802095ea8ff3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>64514</th>\n",
              "      <td>1</td>\n",
              "      <td>I love your list</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6688</th>\n",
              "      <td>0</td>\n",
              "      <td>if you like this will regret it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46970</th>\n",
              "      <td>0</td>\n",
              "      <td>Hey @JustinTrudeau , I read that the executive...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53421</th>\n",
              "      <td>1</td>\n",
              "      <td>Maybe the greatest musical moment in a video w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>844</th>\n",
              "      <td>0</td>\n",
              "      <td>that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24701</th>\n",
              "      <td>1</td>\n",
              "      <td>Thank You @YouTubeIndia @YTCreatorsIndia  for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11040</th>\n",
              "      <td>1</td>\n",
              "      <td>Remember that it was one of the best stealth g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70094</th>\n",
              "      <td>0</td>\n",
              "      <td>@GhostRecon_UK fix your game. The Behemoth is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4307</th>\n",
              "      <td>0</td>\n",
              "      <td>my pc is crying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19280</th>\n",
              "      <td>1</td>\n",
              "      <td>Episode 100! It's a thing! It's a thing that h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43373 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53a569b8-e0a4-49f0-ad6e-802095ea8ff3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-53a569b8-e0a4-49f0-ad6e-802095ea8ff3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-53a569b8-e0a4-49f0-ad6e-802095ea8ff3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Lo92lqyXy0o",
        "outputId": "e3e52b54-5d3c-4d12-f598-d3e38b2e55b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment  sentence\n",
              "False      False       43012\n",
              "           True          361\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True) # dropping empty sentences"
      ],
      "metadata": {
        "id": "4Fv04PYyYFT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "2t6mZ25aQ-K8",
        "outputId": "cfb744c3-40ce-449e-a438-ea61b1b41944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Sentiment                                           sentence\n",
              "64514          1                                   I love your list\n",
              "6688           0                    if you like this will regret it\n",
              "46970          0  Hey @JustinTrudeau , I read that the executive...\n",
              "53421          1  Maybe the greatest musical moment in a video w...\n",
              "844            0                                               that\n",
              "...          ...                                                ...\n",
              "24701          1  Thank You @YouTubeIndia @YTCreatorsIndia  for ...\n",
              "11040          1  Remember that it was one of the best stealth g...\n",
              "70094          0  @GhostRecon_UK fix your game. The Behemoth is ...\n",
              "4307           0                                    my pc is crying\n",
              "19280          1  Episode 100! It's a thing! It's a thing that h...\n",
              "\n",
              "[43012 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f77183f-35e7-465c-b49f-5a3ec965558b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>64514</th>\n",
              "      <td>1</td>\n",
              "      <td>I love your list</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6688</th>\n",
              "      <td>0</td>\n",
              "      <td>if you like this will regret it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46970</th>\n",
              "      <td>0</td>\n",
              "      <td>Hey @JustinTrudeau , I read that the executive...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53421</th>\n",
              "      <td>1</td>\n",
              "      <td>Maybe the greatest musical moment in a video w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>844</th>\n",
              "      <td>0</td>\n",
              "      <td>that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24701</th>\n",
              "      <td>1</td>\n",
              "      <td>Thank You @YouTubeIndia @YTCreatorsIndia  for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11040</th>\n",
              "      <td>1</td>\n",
              "      <td>Remember that it was one of the best stealth g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70094</th>\n",
              "      <td>0</td>\n",
              "      <td>@GhostRecon_UK fix your game. The Behemoth is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4307</th>\n",
              "      <td>0</td>\n",
              "      <td>my pc is crying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19280</th>\n",
              "      <td>1</td>\n",
              "      <td>Episode 100! It's a thing! It's a thing that h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43012 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f77183f-35e7-465c-b49f-5a3ec965558b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f77183f-35e7-465c-b49f-5a3ec965558b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f77183f-35e7-465c-b49f-5a3ec965558b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = df['Sentiment']\n",
        "features = df['sentence']"
      ],
      "metadata": {
        "id": "P3EUU-DNzVaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer\n",
        "using subword tokenizer implementation from Bert model"
      ],
      "metadata": {
        "id": "CTu4-W8ORGAA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QToMl0NanZPr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "bf788e2c-c0c7-4c6b-ae20-fdd594823775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/models/ted_hrlr_translate_pt_en_converter.zip\n",
            "184801/184801 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./ted_hrlr_translate_pt_en_converter.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "model_name = 'ted_hrlr_translate_pt_en_converter'\n",
        "tf.keras.utils.get_file(\n",
        "    f'{model_name}.zip',\n",
        "    f'https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip',\n",
        "    cache_dir='.', cache_subdir='', extract=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5dbGnPXnuI1"
      },
      "outputs": [],
      "source": [
        "tokenizers = tf.saved_model.load(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[item for item in dir(tokenizers) if not item.startswith('_')]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKQlglto-FNG",
        "outputId": "2397d2b1-0a3e-42f4-e9e3-f4ab970df158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['en',\n",
              " 'graph_debug_info',\n",
              " 'pt',\n",
              " 'signatures',\n",
              " 'tensorflow_git_version',\n",
              " 'tensorflow_version']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CexgkIS1lzdt"
      },
      "source": [
        "The `tf.saved_model` contains two text tokenizers, one for English and one for Portuguese. We just need the English one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-PCJijfcZ9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3560b05-8f37-409c-8086-a30d80adad92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['detokenize',\n",
              " 'get_reserved_tokens',\n",
              " 'get_vocab_path',\n",
              " 'get_vocab_size',\n",
              " 'lookup',\n",
              " 'tokenize',\n",
              " 'tokenizer',\n",
              " 'vocab']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "[item for item in dir(tokenizers.en) if not item.startswith('_')]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = features.sample(n=5)\n",
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6ixK1WW0I4q",
        "outputId": "bcb1433e-c90b-46ef-e65a-f21e0b91c23c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49339    Shooting a lil weird, cos I was scoring from s...\n",
              "61600    Just started getting back into GTA online beca...\n",
              "71042    *More of me ogling <unk>. So immersive, so mus...\n",
              "1595     @DuvalMagic @Borderlands game doesn't register...\n",
              "67986    There is a 0% chance that this game will come ...\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_gPC5iwFXfU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1244be43-9eed-4fb9-81ee-d8b3bb2fc894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shooting a lil weird, cos I was scoring from some sick angles.. but i'm seeing something possible exciting with the passing\n"
          ]
        }
      ],
      "source": [
        "text_sample = sample.iloc[0]\n",
        "print(text_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSkM7z8JFaVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "869b783f-569c-4632-f0fd-c17f550300fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded and encoded embeddings:\n",
            "[2, 3530, 37, 48, 1284, 2963, 13, 3455, 88, 45, 84, 55, 3284, 1241, 109, 147, 1907, 6047, 15, 15, 87, 45, 9, 49, 698, 173, 465, 1066, 93, 71, 5373, 3]\n",
            "[2, 112, 232, 361, 193, 156, 43, 2297, 754, 120, 99, 709, 196, 4500, 6540, 89, 71, 718, 2776, 42, 376, 371, 15, 15, 15, 45, 9, 49, 131, 102, 181, 73, 528, 116, 56, 6558, 273, 72, 468, 75, 1831, 92, 3]\n",
            "[2, 1, 121, 74, 114, 51, 651, 826, 1, 6363, 484, 1, 15, 82, 45, 4864, 2430, 13, 82, 1159, 14, 1090, 15, 45, 517, 57, 3283, 88, 376, 2200, 9, 55, 1612, 86, 2228, 13, 104, 140, 234, 15, 15, 15, 15, 81, 1477, 625, 28, 83, 727, 5022, 3564, 76, 15, 15, 15, 72, 115, 149, 37, 4252, 495, 93, 71, 2622, 4552, 2560, 77, 3]\n",
            "[2, 31, 40, 795, 2566, 1361, 6440, 31, 2640, 3172, 1112, 196, 269, 9, 56, 4757, 169, 488, 13, 340, 4304, 105, 3730, 85, 121, 80, 269, 9, 56, 298, 341, 3672, 72, 488, 656, 38, 5567, 1723, 91, 269, 9, 56, 4757, 117, 45, 880, 6690, 27, 16, 1381, 1019, 52, 1607, 3079, 3079, 88, 3]\n",
            "[2, 96, 80, 37, 17, 7, 1079, 75, 81, 1112, 153, 211, 122, 77, 447, 5476, 15, 45, 94, 9, 56, 1009, 73, 528, 76, 77, 2394, 15, 3]\n"
          ]
        }
      ],
      "source": [
        "encoded = tokenizers.en.tokenize(sample)\n",
        "# print(encoded)\n",
        "print('Padded and encoded embeddings:')\n",
        "for row in encoded.to_list():\n",
        "  print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The padded 2 and 3 stands for [START] and [END]"
      ],
      "metadata": {
        "id": "_YBokPtCSfCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded[:, :128]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VrTDyW5xikX",
        "outputId": "4ec0ef86-7b20-4081-c48b-f5880e6520f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 3530, 37, 48, 1284, 2963, 13, 3455, 88, 45, 84, 55, 3284, 1241, 109,\n",
              "  147, 1907, 6047, 15, 15, 87, 45, 9, 49, 698, 173, 465, 1066, 93, 71, 5373,\n",
              "  3]                                                                        ,\n",
              " [2, 112, 232, 361, 193, 156, 43, 2297, 754, 120, 99, 709, 196, 4500, 6540,\n",
              "  89, 71, 718, 2776, 42, 376, 371, 15, 15, 15, 45, 9, 49, 131, 102, 181, 73,\n",
              "  528, 116, 56, 6558, 273, 72, 468, 75, 1831, 92, 3]                        ,\n",
              " [2, 1, 121, 74, 114, 51, 651, 826, 1, 6363, 484, 1, 15, 82, 45, 4864, 2430,\n",
              "  13, 82, 1159, 14, 1090, 15, 45, 517, 57, 3283, 88, 376, 2200, 9, 55, 1612,\n",
              "  86, 2228, 13, 104, 140, 234, 15, 15, 15, 15, 81, 1477, 625, 28, 83, 727,\n",
              "  5022, 3564, 76, 15, 15, 15, 72, 115, 149, 37, 4252, 495, 93, 71, 2622,\n",
              "  4552, 2560, 77, 3]                                                        ,\n",
              " [2, 31, 40, 795, 2566, 1361, 6440, 31, 2640, 3172, 1112, 196, 269, 9, 56,\n",
              "  4757, 169, 488, 13, 340, 4304, 105, 3730, 85, 121, 80, 269, 9, 56, 298,\n",
              "  341, 3672, 72, 488, 656, 38, 5567, 1723, 91, 269, 9, 56, 4757, 117, 45,\n",
              "  880, 6690, 27, 16, 1381, 1019, 52, 1607, 3079, 3079, 88, 3]             ,\n",
              " [2, 96, 80, 37, 17, 7, 1079, 75, 81, 1112, 153, 211, 122, 77, 447, 5476,\n",
              "  15, 45, 94, 9, 56, 1009, 73, 528, 76, 77, 2394, 15, 3]                 ]>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CFS5aAxFdpP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fa3975b-5e20-4b50-df0d-4ad24a83340d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "shooting a lil weird , cos i was scoring from some sick angles . . but i ' m seeing something possible exciting with the passing\n",
            "just started getting back into gta online because my god does rockstar have the incredible taste fo music . . . i ' m going at need to play these tunes again and keep that radio on\n",
            "[UNK] more of me ogling [UNK] unk [UNK] . so immersive , so museum - quality . i hope ubisoft ' s artists are proud , people really should . . . . this urban environment ; they absolutely nailed it . . . and he did a spectacular job with the wilderness in\n",
            "@ duvalmagic @ borderlands game doesn ' t register right sometimes , ammo regen for more isn ' t always working properly and sometimes entire bullets don ' t register when i hit enemies : / fix soon plssssss\n",
            "there is a 0 % chance that this game will come out in 2020 . i can ' t wait to play it in march .\n"
          ]
        }
      ],
      "source": [
        "round_trip = tokenizers.en.detokenize(encoded[:, :128])\n",
        "\n",
        "print('Original text:')\n",
        "for line in round_trip.numpy():\n",
        "  print(line.decode('utf-8'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Yb35sTJcZq9"
      },
      "source": [
        "## Set up a data pipeline with `tf.data`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZHsns5obJhN"
      },
      "source": [
        "The following function takes batches of text as input, and converts them to a format suitable for training. \n",
        "\n",
        "1. It tokenizes them into ragged batches.\n",
        "2. It trims each to be no longer than `MAX_TOKENS`.\n",
        "3. It splits the output (English) tokens into inputs and labels. THese shifted by one step so that the `label` at each location is the id of the next token.\n",
        "4. It converts the `RaggedTensor`s to padded dense `Tensor`s.\n",
        "5. It returns an `(inputs, labels)` pair.\n",
        "\n",
        "NOTE: We will bypass this method in the batch making area and utilize our own method since we are not using `tf.data`"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenizer**\n",
        "Cannot prepare batches as required. I don't know how to fix it."
      ],
      "metadata": {
        "id": "bcjigvyBTNxA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6shgzEck3FiV"
      },
      "outputs": [],
      "source": [
        "MAX_TOKENS=128\n",
        "def prepare_batch(en): # not actually preparing batches\n",
        "    en = tokenizers.en.tokenize(en)\n",
        "    en = en[:, :128] # pads with `.` if the sentence is less than 128 words and strips if more than 128 words\n",
        "    # print(en)\n",
        "    # en_inputs = en[:, :-1].to_tensor()\n",
        "    return en"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences = prepare_batch(features) # batch_size, 128"
      ],
      "metadata": {
        "id": "wtJvpZPFf49x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_tokenized = tokenized_sentences.to_list()"
      ],
      "metadata": {
        "id": "90NMeq3-zE5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list_tokenized), len(labels)"
      ],
      "metadata": {
        "id": "hMN1ugKPgHKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac20836e-f7b1-4af2-e93d-0c5cd6407c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43012, 43012)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(list_tokenized)-43000):\n",
        "  print(list_tokenized[i], labels.iloc[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP2WIe3tl5ie",
        "outputId": "3722ae77-9392-4602-cea7-3b528be3e187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 45, 302, 135, 1261, 3] 1\n",
            "[2, 107, 79, 106, 81, 153, 105, 651, 6526, 76, 3] 0\n",
            "[2, 1366, 31, 112, 530, 271, 6531, 4829, 13, 45, 460, 75, 71, 6696, 5939, 1804, 555, 2689, 74, 5851, 4092, 1479, 8, 315, 2159, 601, 2007, 91, 98, 2486, 455, 49, 1107, 1360, 15, 81, 84, 3613, 159, 284, 37, 5231, 73, 1184, 15, 80, 81, 479, 30, 15, 119, 80, 81, 82, 30, 3310, 147, 5082, 89, 49, 1107, 1360, 92, 101, 2689, 13, 87, 147, 243, 2486, 71, 192, 30, 3] 0\n",
            "[2, 285, 71, 1345, 3247, 368, 77, 37, 383, 59, 6525, 826, 1112, 478, 310, 15, 3] 1\n",
            "[2, 75, 3] 0\n",
            "[2, 38, 795, 6, 77, 230, 6, 6, 1065, 15, 192, 4134, 690, 394, 74, 135, 5252, 2502, 118, 40, 1058, 966, 5496, 1191, 128, 4944, 256, 48, 388, 3721, 685, 30, 3] 0\n",
            "[2, 119, 71, 42, 2713, 145, 79, 98, 106, 765, 959, 5404, 19, 15, 45, 528, 81, 1112, 72, 45, 9, 49, 3866, 75, 76, 9, 55, 100, 205, 100, 76, 80, 15, 3] 1\n",
            "[2, 31, 1470, 6401, 1163, 5140, 1572, 31, 1470, 6401, 1163, 35, 6957, 31, 57, 3283, 88, 376, 2200, 88, 1575, 5171, 31, 57, 3283, 88, 376, 2200, 31, 57, 3283, 88, 376, 2200, 35, 6957, 4428, 161, 111, 2838, 73, 193, 71, 52, 138, 16, 1156, 771, 85, 332, 160, 76, 84, 71, 209, 110, 75, 79, 4952, 223, 76, 4, 96, 84, 883, 154, 181, 13, 76, 9, 55, 291, 705, 72, 6600, 4, 3] 0\n",
            "[2, 80, 76, 929, 5070, 138, 122, 71, 338, 73, 105, 684, 795, 240, 765, 959, 5404, 19, 82, 45, 9, 49, 98, 112, 1488, 42, 388, 6432, 13, 3133, 4095, 72, 49, 392, 684, 71, 283, 671, 71, 48, 6494, 484, 6419, 30, 3] 0\n",
            "[2, 273, 19, 31, 2640, 3172, 59, 271, 1192, 3] 0\n",
            "[2, 393, 15, 43, 2297, 5751, 347, 491, 113, 6964, 347, 491, 15, 87, 83, 9, 105, 101, 31, 4500, 6540, 5140, 5158, 13, 82, 76, 9, 55, 37, 1508, 85, 124, 13, 5405, 3] 1\n",
            "[2, 452, 119, 6355, 71, 42, 388, 6432, 442, 3674, 77, 4349, 15, 3455, 5162, 1305, 803, 31, 41, 1107, 5171, 88, 3072, 6432, 85, 910, 21, 74, 71, 190, 6355, 1064, 15, 15, 15, 15, 169, 463, 169, 93, 1184, 77, 5400, 1163, 15, 3] 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e7hKcxn6-zd"
      },
      "source": [
        "## Copied code \n",
        "we need to change it up a bit so we can use same definitions for our own classification problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS75Y-9-lkzn"
      },
      "source": [
        "### Define the Embedding and Positional encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Rz82wEs5biZ"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(length, depth):\n",
        "  depth = depth/2\n",
        "\n",
        "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
        "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
        "  \n",
        "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
        "  angle_rads = positions * angle_rates      # (pos, depth)\n",
        "\n",
        "  pos_encoding = np.concatenate(\n",
        "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "      axis=-1) \n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_encoding = positional_encoding(length=2048, depth=512)\n",
        "temp_encoding"
      ],
      "metadata": {
        "id": "z97IJsy575hJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccc11e7a-8ca8-408e-d2ed-5152eb6bb577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2048, 512), dtype=float32, numpy=\n",
              "array([[ 0.        ,  0.        ,  0.        , ...,  1.        ,\n",
              "         1.        ,  1.        ],\n",
              "       [ 0.84147096,  0.8218562 ,  0.8019618 , ...,  1.        ,\n",
              "         1.        ,  1.        ],\n",
              "       [ 0.9092974 ,  0.9364147 ,  0.95814437, ...,  1.        ,\n",
              "         1.        ,  1.        ],\n",
              "       ...,\n",
              "       [ 0.17589758, -0.18608274, -0.7070546 , ...,  0.9741639 ,\n",
              "         0.97595036,  0.97761387],\n",
              "       [-0.7333133 ,  0.7014913 ,  0.1447375 , ...,  0.9741387 ,\n",
              "         0.97592694,  0.97759205],\n",
              "       [-0.9683193 ,  0.98535496,  0.8799798 , ...,  0.9741135 ,\n",
              "         0.9759035 ,  0.9775702 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_encoding[tf.newaxis, :128, :].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmtqpoFW95xX",
        "outputId": "abc656ba-352e-46ed-be38-7e4c32f93d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 128, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "838tmM1cm9cB"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "  def __init__(self, vocab_size, d_model):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True) \n",
        "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
        "\n",
        "  def compute_mask(self, *args, **kwargs):\n",
        "    return self.embedding.compute_mask(*args, **kwargs)\n",
        "\n",
        "  def call(self, x):\n",
        "    length = tf.shape(x)[1]\n",
        "    x = self.embedding(x)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "    return x # (batch_size, length-of-signal, 512)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((400, 128, 512))\n",
        "y = np.zeros((1, 128, 512))"
      ],
      "metadata": {
        "id": "j69lsiUpBDAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(4, 3, 2)\n",
        "y = np.random.rand(1, 3, 2)\n"
      ],
      "metadata": {
        "id": "glzhCWdSCb_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRrflPoSDE-q",
        "outputId": "91aa39da-3c2f-4363-f2e6-8cab7e7a0c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[0.95609057, 0.60270507],\n",
              "         [0.51131414, 0.71017839],\n",
              "         [0.9538461 , 0.21263245]],\n",
              " \n",
              "        [[0.6372833 , 0.14766658],\n",
              "         [0.60528041, 0.24988174],\n",
              "         [0.03645899, 0.9000626 ]],\n",
              " \n",
              "        [[0.66726868, 0.68453458],\n",
              "         [0.18968806, 0.86797481],\n",
              "         [0.43211758, 0.7504659 ]],\n",
              " \n",
              "        [[0.40709853, 0.90729841],\n",
              "         [0.26381697, 0.56954289],\n",
              "         [0.46140479, 0.01489403]]]), array([[[0.02513828, 0.58679921],\n",
              "         [0.29969024, 0.72462405],\n",
              "         [0.53957241, 0.83326605]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x+y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1ElC4cDC-uq",
        "outputId": "78696c37-98ff-4855-d6d5-fa5fd7decf71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.98122885, 1.18950428],\n",
              "        [0.81100438, 1.43480244],\n",
              "        [1.49341851, 1.0458985 ]],\n",
              "\n",
              "       [[0.66242158, 0.73446579],\n",
              "        [0.90497066, 0.97450579],\n",
              "        [0.5760314 , 1.73332866]],\n",
              "\n",
              "       [[0.69240696, 1.2713338 ],\n",
              "        [0.4893783 , 1.59259886],\n",
              "        [0.97168999, 1.58373195]],\n",
              "\n",
              "       [[0.43223681, 1.49409762],\n",
              "        [0.56350722, 1.29416694],\n",
              "        [1.00097719, 0.84816008]]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.cast(512, tf.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fbrswnyk9EjM",
        "outputId": "4768afcb-90a5-49c8-eeef-ddf68634c5b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=512.0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizers.en.get_vocab_size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBmeI00p3PY9",
        "outputId": "661cb359-4326-42d4-c3f7-14164930f8a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=7010>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_layer = tf.keras.layers.Embedding(7010, 512, mask_zero=True)\n",
        "# help(temp_layer)"
      ],
      "metadata": {
        "id": "g6t0WrNH21Ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_model = tf.keras.Sequential()\n",
        "temp_layer = tf.keras.layers.Embedding(1000, 64, input_length=10, mask_zero=True)\n",
        "temp_model.add(temp_layer)\n",
        "# The model will take as input an integer matrix of size (batch,\n",
        "# input_length), and the largest integer (i.e. word index) in the input\n",
        "# should be no larger than 999 (vocabulary size).\n",
        "# Now model.output_shape is (None, 10, 64), where `None` is the batch\n",
        "# dimension.\n",
        "input_array = np.random.randint(1000, size=(1, 10))\n",
        "temp_model.compile('rmsprop', 'mse')\n",
        "output_array = temp_model.predict(input_array)\n",
        "# print(output_array)\n",
        "print(output_array.shape)\n",
        "#(1, 10, 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs5TYJmt4126",
        "outputId": "946c3ace-e9d9-4ee7-b4f8-1594a84064d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 62ms/step\n",
            "(1, 10, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(temp_layer.compute_mask(input_array, mask_zero=True)) # would not work as this is just for forwarding the compute_mask"
      ],
      "metadata": {
        "id": "MB4eo7nb5F4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfz-EaCEDfUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "709c9440-6935-4089-ab13-50fc5bd36dfb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.PositionalEmbedding at 0x7f6a92d33d50>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "embed_en = PositionalEmbedding(vocab_size=tokenizers.en.get_vocab_size(), d_model=512)\n",
        "embed_en"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded.to_tensor()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SFJD1RjHF-G",
        "outputId": "26a91c27-d5ef-46d6-845f-a337c20261eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 68), dtype=int64, numpy=\n",
              "array([[   2, 3530,   37,   48, 1284, 2963,   13, 3455,   88,   45,   84,\n",
              "          55, 3284, 1241,  109,  147, 1907, 6047,   15,   15,   87,   45,\n",
              "           9,   49,  698,  173,  465, 1066,   93,   71, 5373,    3,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   2,  112,  232,  361,  193,  156,   43, 2297,  754,  120,   99,\n",
              "         709,  196, 4500, 6540,   89,   71,  718, 2776,   42,  376,  371,\n",
              "          15,   15,   15,   45,    9,   49,  131,  102,  181,   73,  528,\n",
              "         116,   56, 6558,  273,   72,  468,   75, 1831,   92,    3,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   2,    1,  121,   74,  114,   51,  651,  826,    1, 6363,  484,\n",
              "           1,   15,   82,   45, 4864, 2430,   13,   82, 1159,   14, 1090,\n",
              "          15,   45,  517,   57, 3283,   88,  376, 2200,    9,   55, 1612,\n",
              "          86, 2228,   13,  104,  140,  234,   15,   15,   15,   15,   81,\n",
              "        1477,  625,   28,   83,  727, 5022, 3564,   76,   15,   15,   15,\n",
              "          72,  115,  149,   37, 4252,  495,   93,   71, 2622, 4552, 2560,\n",
              "          77,    3],\n",
              "       [   2,   31,   40,  795, 2566, 1361, 6440,   31, 2640, 3172, 1112,\n",
              "         196,  269,    9,   56, 4757,  169,  488,   13,  340, 4304,  105,\n",
              "        3730,   85,  121,   80,  269,    9,   56,  298,  341, 3672,   72,\n",
              "         488,  656,   38, 5567, 1723,   91,  269,    9,   56, 4757,  117,\n",
              "          45,  880, 6690,   27,   16, 1381, 1019,   52, 1607, 3079, 3079,\n",
              "          88,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   2,   96,   80,   37,   17,    7, 1079,   75,   81, 1112,  153,\n",
              "         211,  122,   77,  447, 5476,   15,   45,   94,    9,   56, 1009,\n",
              "          73,  528,   76,   77, 2394,   15,    3,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is where the error pops up. I assume it is because of the way we are preparing batches.\n",
        "\n",
        "# embed_en(encoded)\n",
        "embed_en(encoded.to_tensor()).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3M1i9ThT5cN",
        "outputId": "819f3a16-0a2a-41c2-92e7-4870c906a7a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([5, 68, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLjScSWQv9M5"
      },
      "source": [
        "### Define the feed forward network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz0HBopX_VdU"
      },
      "source": [
        "Define a function for the point-wise feed-forward network that you'll use later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yb-IV0Nlzd0"
      },
      "source": [
        "The network consists of two linear layers (`tf.keras.layers.Dense`) with a ReLU activation in-between:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ET7xLt0yCT6Z"
      },
      "outputs": [],
      "source": [
        "def point_wise_feed_forward_network(\n",
        "  d_model, # Input/output dimensionality.\n",
        "  dff # Inner-layer dimensionality.\n",
        "  ):\n",
        "\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # Shape `(batch_size, seq_len, dff)`.\n",
        "      tf.keras.layers.Dense(d_model)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "  ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFv-FNYUmvpn"
      },
      "source": [
        "### Define the encoder layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncyS-Ms3i2x_"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,*,\n",
        "               d_model, # Input/output dimensionality.\n",
        "               num_attention_heads,\n",
        "               dff, # Inner-layer dimensionality.\n",
        "               dropout_rate=0.1\n",
        "               ):\n",
        "    super().__init__()\n",
        "\n",
        "\n",
        "    # Multi-head self-attention.\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(\n",
        "        num_heads=num_attention_heads,\n",
        "        key_dim=d_model, # Size of each attention head for query Q and key K.\n",
        "        dropout=dropout_rate,\n",
        "        )\n",
        "    # Point-wise feed-forward network.\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    # Layer normalization.\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    # Dropout for the point-wise feed-forward network.\n",
        "    self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    # A boolean mask.\n",
        "    if mask is not None:\n",
        "      mask1 = mask[:, :, None]\n",
        "      mask2 = mask[:, None, :]\n",
        "      attention_mask = mask1 & mask2\n",
        "    else:\n",
        "      attention_mask = None\n",
        "\n",
        "    # Multi-head self-attention output (`tf.keras.layers.MultiHeadAttention `).\n",
        "    attn_output = self.mha(\n",
        "        query=x,  # Query Q tensor.\n",
        "        value=x,  # Value V tensor.\n",
        "        key=x,  # Key K tensor.\n",
        "        attention_mask=attention_mask, # A boolean mask that prevents attention to certain positions.\n",
        "        training=training, # A boolean indicating whether the layer should behave in training mode.\n",
        "        )\n",
        "\n",
        "    # Multi-head self-attention output after layer normalization and a residual/skip connection.\n",
        "    out1 = self.layernorm1(x + attn_output)  # Shape `(batch_size, input_seq_len, d_model)`\n",
        "\n",
        "    # Point-wise feed-forward network output.\n",
        "    ffn_output = self.ffn(out1)  # Shape `(batch_size, input_seq_len, d_model)`\n",
        "    ffn_output = self.dropout1(ffn_output, training=training)\n",
        "    # Point-wise feed-forward network output after layer normalization and a residual skip connection.\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # Shape `(batch_size, input_seq_len, d_model)`.\n",
        "\n",
        "    return out2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_encoder_layer = EncoderLayer(d_model=512, num_attention_heads=8, dff=2048)\n",
        "\n",
        "sample_encoder_layer_output = sample_encoder_layer(\n",
        "    tf.random.uniform((2, 3, 512)), training=False, mask=None)\n",
        "\n",
        "# Print the shape.\n",
        "print(sample_encoder_layer_output.shape)  # Shape `(batch_size, input_seq_len, d_model)`."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVRCcp1oOe8H",
        "outputId": "56539463-ab95-4144-86ac-d93b62c5dbe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 3, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE1H51Ajm0q1"
      },
      "source": [
        "### Define the encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpEox7gJ8FCI"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self,\n",
        "               *,\n",
        "               num_layers,\n",
        "               d_model, # Input/output dimensionality.\n",
        "               num_attention_heads,\n",
        "               dff, # Inner-layer dimensionality.\n",
        "               input_vocab_size, # Input (Portuguese) vocabulary size.\n",
        "               dropout_rate=0.1\n",
        "               ):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # Embeddings + Positional encoding\n",
        "    self.pos_embedding = PositionalEmbedding(input_vocab_size, d_model)\n",
        "\n",
        "    # Encoder layers.\n",
        "    self.enc_layers = [\n",
        "        EncoderLayer(\n",
        "          d_model=d_model,\n",
        "          num_attention_heads=num_attention_heads,\n",
        "          dff=dff,\n",
        "          dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "    # Dropout.\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  # Masking.\n",
        "  def compute_mask(self, x, previous_mask=None):\n",
        "    return self.pos_embedding.compute_mask(x, previous_mask)\n",
        "\n",
        "  def call(self, x, training):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "\n",
        "    # Sum up embeddings and positional encoding.\n",
        "    mask = self.compute_mask(x)\n",
        "    x = self.pos_embedding(x)  # Shape `(batch_size, input_seq_len, d_model)`.\n",
        "    # Add dropout.\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    # N encoder layers.\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "    # experimental thing, may not work\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "    return x  # Shape `(batch_size, input_seq_len, d_model)`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the encoder.\n",
        "sample_encoder = Encoder(\n",
        "    num_layers=8,\n",
        "    d_model=512,\n",
        "    num_attention_heads=8,\n",
        "    dff=2048,\n",
        "    input_vocab_size=7010)\n",
        "\n",
        "# Set the test input.\n",
        "sample_encoder_output = sample_encoder(encoded.to_tensor(),\n",
        "                                       training=False)\n",
        "\n",
        "# Print the shape.\n",
        "print(encoded.to_tensor().shape)\n",
        "print(sample_encoder_output.shape)  # Shape `(batch_size, input_seq_len, d_model)`."
      ],
      "metadata": {
        "id": "cp5jWxF9UaCa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f93cfe98-f213-4e9c-815b-6eeb16dd376a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 68)\n",
            "(5, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=(129)),\n",
        "    sample_encoder\n",
        "])"
      ],
      "metadata": {
        "id": "sNZlioSXQASk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keArSCgQQVD3",
        "outputId": "73bb6b05-2218-47fd-b64f-d084374544d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder (Encoder)           (None, 1)                 87614464  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,614,464\n",
            "Trainable params: 87,614,464\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[item for item in dir(model) if not item.startswith('_')]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2qUsi8IIRfSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.input_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NCb-S8SR-a2",
        "outputId": "15473609-b4fe-4c7f-cc51-7942ff165920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences.to_tensor().shape # iske batches bnane hain..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXeuxu3ASHbu",
        "outputId": "2665c99b-843b-4d15-938c-488729313709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([43012, 129])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 4\n",
        "d_model = 129\n",
        "dff = 512\n",
        "num_attention_heads = 8\n",
        "dropout_rate = 0.1"
      ],
      "metadata": {
        "id": "5-jTpAyBSPdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=(128)),\n",
        "    Encoder(num_layers = 4, d_model = 128, dff = 512, num_attention_heads = 8, input_vocab_size=tokenizers.en.get_vocab_size())\n",
        "])"
      ],
      "metadata": {
        "id": "CZWvgCuteGj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = np.random.rand(1, 128)\n",
        "# print(input.shape)\n",
        "target = tf.constant([[1,2,3, 0]])\n",
        "\n",
        "x = model((input))\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41IxWLzFenCo",
        "outputId": "b10457b0-8e19-4b27-fd79-f540f93d7db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.45408416]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3PR-31gfbBw",
        "outputId": "2dedca3b-44e3-410d-a946-4c8a111bd029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_2 (Encoder)         (None, 1)                 3536128   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,536,128\n",
            "Trainable params: 3,536,128\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"binary_accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "HffYO-bwg76r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3iUG_YriF5i",
        "outputId": "d732332c-f603-497e-baf4-d19bd4f22c58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    22358\n",
              "1    20654\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences.to_tensor()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8HslnUDies9",
        "outputId": "c7dee9ec-102b-4eed-de09-c0544e24739c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(43012, 128), dtype=int64, numpy=\n",
              "array([[   2,   45,  302, ...,    0,    0,    0],\n",
              "       [   2,  107,   79, ...,    0,    0,    0],\n",
              "       [   2, 1366,   31, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [   2,   31,   43, ...,    0,    0,    0],\n",
              "       [   2,   99,   52, ...,    0,    0,    0],\n",
              "       [   2, 5681,  551, ...,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(labels)"
      ],
      "metadata": {
        "id": "MdArge4hiluS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# error!\n",
        "history = model.fit(\n",
        "    tokenized_sentences.to_tensor(),\n",
        "    epochs=200,\n",
        "    validation_data=labels\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "LExwQVPth3Av",
        "outputId": "904565be-43b1-45f2-b3a4-26c4bff6aa67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-c6ab3590c493>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtokenized_sentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1536\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m         raise ValueError(\n\u001b[0;32m-> 1538\u001b[0;31m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1539\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-LKXJplXh_V5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}